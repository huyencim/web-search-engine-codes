{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7WARPC3RBw3",
        "outputId": "fee8ad33-81bc-4e9a-89d8-917f42330627",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'https://searchengineplaces.com.tr/': 0.019999999999999997, 'http://www.searchengineplaces.com.tr/travel_guide.html': 0.14780429869056003, 'http://www.searchengineplaces.com.tr/seymarecommends.html': 0.073060618584064, 'http://www.searchengineplaces.com.tr/oktayrecommends.html': 0.073060618584064, 'http://www.searchengineplaces.com.tr/istanbul.html': 0.17460832634470402, 'http://www.searchengineplaces.com.tr/galata_tower.html': 0.09025810358272002, 'http://www.searchengineplaces.com.tr/maidens_tower.html': 0.09025810358272002, 'http://www.searchengineplaces.com.tr/konya.html': 0.073060618584064, 'http://www.searchengineplaces.com.tr/mevlana.html': 0.04928445079552, 'http://www.searchengineplaces.com.tr/ankara.html': 0.043776167788544}\n"
          ]
        }
      ],
      "source": [
        "def getPage(url):\n",
        "  try:\n",
        "    import urllib.request\n",
        "    page = urllib.request.urlopen(url).read()\n",
        "    page = page.decode(\"utf-8\")\n",
        "    return page\n",
        "  except:\n",
        "    return \"\"\n",
        "\n",
        "def get_next_target(page):\n",
        "    start_link = page.find('<a href=')\n",
        "    if start_link == -1:\n",
        "        return None, 0\n",
        "    start_quote = page.find('\"', start_link)\n",
        "    end_quote = page.find('\"', start_quote+1)\n",
        "    url = page[start_quote + 1:end_quote]\n",
        "    return url, end_quote\n",
        "\n",
        "def get_all_links(page):\n",
        "    links = []\n",
        "    while True:\n",
        "      url, endpos = get_next_target(page)\n",
        "      if url:\n",
        "        links.append(url)\n",
        "        page = page[endpos:]\n",
        "      else:\n",
        "        break\n",
        "    return links\n",
        "\n",
        "def union(p,q):\n",
        "  for e in q:\n",
        "    if e not in p:\n",
        "      p.append(e)\n",
        "\n",
        "def add_to_index(index, keyword, url):\n",
        "  if keyword in index:\n",
        "    index[keyword].append(url)\n",
        "  else:\n",
        "    index[keyword] = [url]\n",
        "\n",
        "def addPageToIndex(index, url, content):\n",
        "  words = content.split()\n",
        "  for word in words:\n",
        "    add_to_index(index, word, url)\n",
        "\n",
        "def crawlWeb(seed):\n",
        "  tocrawl = [seed]\n",
        "  crawled = []\n",
        "  index = {}\n",
        "  graph = {}\n",
        "\n",
        "  while tocrawl:\n",
        "    page = tocrawl.pop()\n",
        "    if page not in crawled:\n",
        "      content = getPage(page)\n",
        "      addPageToIndex(index, page, content)\n",
        "      outlinks = get_all_links(content)\n",
        "      graph [page] = outlinks\n",
        "      union(tocrawl, get_all_links(content))\n",
        "      crawled.append(page)\n",
        "\n",
        "  return index, graph\n",
        "\n",
        "def computeRanks(graph):\n",
        "  d = 0.8\n",
        "  N = len(graph) # number of pages\n",
        "  numloops = 10 # effects the accuracy\n",
        "  ranks = {}\n",
        "\n",
        "  for page in graph :\n",
        "    ranks[page] = 1/N\n",
        "\n",
        "  for i in range (0, numloops):\n",
        "    newranks = {}\n",
        "    for page in graph :\n",
        "      newrank = (1-d)/N\n",
        "      for node in graph :\n",
        "        if page in graph[node]:\n",
        "          newrank = newrank + d*(ranks[node]/len(graph[node]))\n",
        "      newranks[page] = newrank\n",
        "    ranks = newranks\n",
        "  return newranks\n",
        "\n",
        "\n",
        "index , graph = crawlWeb(\"https://searchengineplaces.com.tr/\")\n",
        "ranks = computeRanks(graph)\n",
        "print(ranks)\n"
      ]
    }
  ]
}